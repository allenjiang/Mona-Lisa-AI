{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal is to answer the question: can a machine detect a person's gender based on their tweet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Get twitter data\n",
    "2. Clean\n",
    "3. Analyze and visualize\n",
    "4. Build model\n",
    "5. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import libraries for WordCloud\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.api.API"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to twitter API\n",
    "path_auth = '/Users/allenj/Documents/Keys/auth_twitter.json'\n",
    "auth = json.loads(open(path_auth).read())\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "my_consumer_key = auth['my_consumer_key']\n",
    "my_consumer_secret = auth['my_consumer_secret']\n",
    "my_access_token = auth['your_access_token']\n",
    "my_access_token_secret = auth['my_access_token_secret']\n",
    "\n",
    "auth = tw.OAuthHandler(my_consumer_key, my_consumer_secret)\n",
    "auth.set_access_token(my_access_token, my_access_token_secret)\n",
    "api = tw.API(auth)\n",
    "\n",
    "type(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>followers_millions</th>\n",
       "      <th>activity</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aaker</td>\n",
       "      <td>Jennifer Aaker</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AdamMGrant</td>\n",
       "      <td>Adam Grant</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Adele</td>\n",
       "      <td>Adele</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Musician</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>akshaykumar</td>\n",
       "      <td>Akshay Kumar</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Actor</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aliciakeys</td>\n",
       "      <td>Alicia Keys</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Musician</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>taylorswift13</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>Musician</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>Ellen DeGeneres</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>Comedian and television hostess</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>UnhealthyTruth</td>\n",
       "      <td>Robyn O'Brien</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>VeronicaMcG</td>\n",
       "      <td>Veronica McGregor</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Rapper</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user               name  gender followers_millions  \\\n",
       "0            aaker     Jennifer Aaker       1                  -   \n",
       "1       AdamMGrant         Adam Grant       0                  -   \n",
       "2            Adele              Adele       1                 27   \n",
       "3      akshaykumar       Akshay Kumar       0                 36   \n",
       "4       aliciakeys        Alicia Keys       1                 30   \n",
       "..             ...                ...     ...                ...   \n",
       "69   taylorswift13       Taylor Swift       1                 86   \n",
       "70    TheEllenShow    Ellen DeGeneres       1                 80   \n",
       "71  UnhealthyTruth      Robyn O'Brien       1                  -   \n",
       "72     VeronicaMcG  Veronica McGregor       1                  -   \n",
       "73      wizkhalifa        Wiz Khalifa       0                 36   \n",
       "\n",
       "                           activity         country  \n",
       "0                                 -               -  \n",
       "1                                 -               -  \n",
       "2                          Musician  United Kingdom  \n",
       "3                             Actor           India  \n",
       "4                          Musician   United States  \n",
       "..                              ...             ...  \n",
       "69                         Musician   United States  \n",
       "70  Comedian and television hostess   United States  \n",
       "71                                -               -  \n",
       "72                                -               -  \n",
       "73                           Rapper   United States  \n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload list of desired users\n",
    "# Gender 0 = male, 1 = female\n",
    "users = pd.read_csv('../Data/twitter-users.csv')\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@aunder @KatieS @sarahcpr Done!  Also @3GS @di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@KatieS @sarahcpr You two both joined Humor: S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aaker</td>\n",
       "      <td>Today was the last day of class. Feeling nosta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@karagoldin Your masks are OUTSTANDING. we lov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aaker</td>\n",
       "      <td>Blown away by the comic SWAT team that joined ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Oh yea roll somethin and get tha day started.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>At tha rate we‚Äôre goin a lawyer gon take joe c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Get that @McQueenVF #McQueenTeam https://t.co/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Contact ft @Tyga out now @Spotify \\n\\nhttps://...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Roll something and get the day started</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8323 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user                                               text  gender\n",
       "0        aaker  @aunder @KatieS @sarahcpr Done!  Also @3GS @di...       1\n",
       "1        aaker  @KatieS @sarahcpr You two both joined Humor: S...       1\n",
       "2        aaker  Today was the last day of class. Feeling nosta...       1\n",
       "3        aaker  @karagoldin Your masks are OUTSTANDING. we lov...       1\n",
       "4        aaker  Blown away by the comic SWAT team that joined ...       1\n",
       "..         ...                                                ...     ...\n",
       "61  wizkhalifa      Oh yea roll somethin and get tha day started.       0\n",
       "62  wizkhalifa  At tha rate we‚Äôre goin a lawyer gon take joe c...       0\n",
       "63  wizkhalifa  Get that @McQueenVF #McQueenTeam https://t.co/...       0\n",
       "64  wizkhalifa  Contact ft @Tyga out now @Spotify \\n\\nhttps://...       0\n",
       "65  wizkhalifa             Roll something and get the day started       0\n",
       "\n",
       "[8323 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get collection of tweets from these usernames and store it into a new dataframe\n",
    "list = []\n",
    "\n",
    "for index, row in users.iterrows():\n",
    "    tweets = api.user_timeline(screen_name=row['user'], count=150, include_rts=False)\n",
    "    users_text = [[tweet.user.screen_name, tweet.text, row['gender']] for tweet in tweets]\n",
    "    tweet_text = pd.DataFrame(data=users_text, \n",
    "                        columns=[\"user\", \"text\", \"gender\"])\n",
    "    list.append(tweet_text)\n",
    "\n",
    "# Merge the list    \n",
    "tweets = pd.concat(list) \n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@aunder @KatieS @sarahcpr Done!  Also @3GS @di...</td>\n",
       "      <td>1</td>\n",
       "      <td>@aunder @KatieS @sarahcpr Done!  Also @3GS @di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@KatieS @sarahcpr You two both joined Humor: S...</td>\n",
       "      <td>1</td>\n",
       "      <td>@KatieS @sarahcpr You two both joined Humor: S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aaker</td>\n",
       "      <td>Today was the last day of class. Feeling nosta...</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was the last day of class. Feeling nosta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aaker</td>\n",
       "      <td>@karagoldin Your masks are OUTSTANDING. we lov...</td>\n",
       "      <td>1</td>\n",
       "      <td>@karagoldin Your masks are OUTSTANDING. we lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aaker</td>\n",
       "      <td>Blown away by the comic SWAT team that joined ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Blown away by the comic SWAT team that joined ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Oh yea roll somethin and get tha day started.</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh yea roll somethin and get tha day started.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>At tha rate we‚Äôre goin a lawyer gon take joe c...</td>\n",
       "      <td>0</td>\n",
       "      <td>At tha rate we‚Äôre goin a lawyer gon take joe c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Get that @McQueenVF #McQueenTeam https://t.co/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Get that @McQueenVF #McQueenTeam https://t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Contact ft @Tyga out now @Spotify \\n\\nhttps://...</td>\n",
       "      <td>0</td>\n",
       "      <td>Contact ft @Tyga out now @Spotify \\n\\nhttps://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>Roll something and get the day started</td>\n",
       "      <td>0</td>\n",
       "      <td>Roll something and get the day started</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8323 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user                                               text  gender  \\\n",
       "0        aaker  @aunder @KatieS @sarahcpr Done!  Also @3GS @di...       1   \n",
       "1        aaker  @KatieS @sarahcpr You two both joined Humor: S...       1   \n",
       "2        aaker  Today was the last day of class. Feeling nosta...       1   \n",
       "3        aaker  @karagoldin Your masks are OUTSTANDING. we lov...       1   \n",
       "4        aaker  Blown away by the comic SWAT team that joined ...       1   \n",
       "..         ...                                                ...     ...   \n",
       "61  wizkhalifa      Oh yea roll somethin and get tha day started.       0   \n",
       "62  wizkhalifa  At tha rate we‚Äôre goin a lawyer gon take joe c...       0   \n",
       "63  wizkhalifa  Get that @McQueenVF #McQueenTeam https://t.co/...       0   \n",
       "64  wizkhalifa  Contact ft @Tyga out now @Spotify \\n\\nhttps://...       0   \n",
       "65  wizkhalifa             Roll something and get the day started       0   \n",
       "\n",
       "                                           clean_text  \n",
       "0   @aunder @KatieS @sarahcpr Done!  Also @3GS @di...  \n",
       "1   @KatieS @sarahcpr You two both joined Humor: S...  \n",
       "2   Today was the last day of class. Feeling nosta...  \n",
       "3   @karagoldin Your masks are OUTSTANDING. we lov...  \n",
       "4   Blown away by the comic SWAT team that joined ...  \n",
       "..                                                ...  \n",
       "61      Oh yea roll somethin and get tha day started.  \n",
       "62  At tha rate we‚Äôre goin a lawyer gon take joe c...  \n",
       "63  Get that @McQueenVF #McQueenTeam https://t.co/...  \n",
       "64  Contact ft @Tyga out now @Spotify \\n\\nhttps://...  \n",
       "65             Roll something and get the day started  \n",
       "\n",
       "[8323 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['clean_text'] = tweets['text']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of datapoints per person\n",
    "tweets.groupby([\"user\", \"gender\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text by removing things\n",
    "def remove_pattern(text,pattern):\n",
    "    \n",
    "    # re.findall() finds the pattern i.e @user and puts it in a list for further task\n",
    "    r = re.findall(pattern,text)\n",
    "    \n",
    "    # re.sub() removes @user from the sentences in the dataset\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Remove @ symbol, URL links, and \"&amp;\"\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['text'], \"@[\\w]*\") #removes all @\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"&amp;\")\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"#[\\w]*\") #removes all hashtags\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"https?:\\/\\/.*[\\r\\n]*\")\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>My statement on the death of George Floyd: htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>statement death George Floyd</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>If you believe in a more just, more generous, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>believe more just more generous more democrati...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>On Memorial Day, we honor those who gave all f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Memorial honor those gave That takes different...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>And here‚Äôs more on the approach Sweden has tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>here more approach Sweden taken which differs ...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>South Korea has focused on testing to guard ag...</td>\n",
       "      <td>0</td>\n",
       "      <td>South Korea focused testing guard against outb...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         user                                               text  \\\n",
       "0           0  BarackObama  My statement on the death of George Floyd: htt...   \n",
       "1           1  BarackObama  If you believe in a more just, more generous, ...   \n",
       "2           2  BarackObama  On Memorial Day, we honor those who gave all f...   \n",
       "3           3  BarackObama  And here‚Äôs more on the approach Sweden has tak...   \n",
       "4           4  BarackObama  South Korea has focused on testing to guard ag...   \n",
       "\n",
       "   gender                                         clean_text  length  \n",
       "0       0                       statement death George Floyd      66  \n",
       "1       0  believe more just more generous more democrati...     140  \n",
       "2       0  Memorial honor those gave That takes different...     140  \n",
       "3       0  here more approach Sweden taken which differs ...     117  \n",
       "4       0  South Korea focused testing guard against outb...      87  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = pd.read_csv('../Data/twitter-testset.csv')\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0736b0aed7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Clean text by removing things\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/twitter-testset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"@[\\w]*\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#removes all @\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https?:\\/\\/.*[\\r\\n]*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&amp;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_pattern' is not defined"
     ]
    }
   ],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Clean text by removing things\n",
    "testset = pd.read_csv('../Data/twitter-testset.csv')\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['text'], \"@[\\w]*\") #removes all @\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"https?:\\/\\/.*[\\r\\n]*\")\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"&amp;\")\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"#[\\w]*\") #removes all hashtags\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation, numbers, and special characters\n",
    "tweets['clean_text'] = tweets['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Remove punctuation, numbers, and special characters\n",
    "testset['clean_text'] = testset['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove short words less than 3\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Remove short words less than 2\n",
    "testset['clean_text'] = testset['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "testset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column to count length of clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count length of characters\n",
    "tweets['length'] = tweets['clean_text'].apply(len)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Count length\n",
    "testset['length'] = testset['clean_text'].apply(len)\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows in training data that have less than desired text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tweets['length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where length <= 30\n",
    "tweets = tweets[tweets.length > 30]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tweets['length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize, stem, and stich back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenization\n",
    "# tokenized_tweet = tweets['clean_text'].apply(lambda x: x.split())\n",
    "# tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do the same for the testing dataset\n",
    "# # Tokenization\n",
    "# tokenized_testset = testset['clean_text'].apply(lambda x: x.split())\n",
    "# tokenized_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stemming\n",
    "# ps = PorterStemmer()\n",
    "# tokenized_tweet = tokenized_tweet.apply(lambda x: [ps.stem(i) for i in x])\n",
    "# tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do the same for the testing dataset\n",
    "# # Stemming\n",
    "# ps = PorterStemmer()\n",
    "# tokenized_testset = tokenized_testset.apply(lambda x: [ps.stem(i) for i in x])\n",
    "# tokenized_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stich tokens back together\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "          \n",
    "# testset['clean_text'] = tokenized_tweet\n",
    "# testset['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stich tokens back together\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "          \n",
    "# testset['clean_text'] = tokenized_tweet\n",
    "# testset['clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Selectioin and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>00ano5u6jn</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010101</th>\n",
       "      <th>01aqjixwaw</th>\n",
       "      <th>01h</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô</th>\n",
       "      <th>„Åä„Åä„Åç„Å´</th>\n",
       "      <th>„Éï„É¨„ÉÉ„Ç∑„É•„Éç„Çπ„Éê„Éº„Ç¨„Éº</th>\n",
       "      <th>ÂçÉËëâ</th>\n",
       "      <th>Â§ßÈò™</th>\n",
       "      <th>Êù±‰∫¨</th>\n",
       "      <th>Á•ûÊà∏</th>\n",
       "      <th>ùìêùì´ùì∏ùìøùìÆ</th>\n",
       "      <th>ùìóùìÆùì™ùì≠</th>\n",
       "      <th>ùì¶ùì™ùìΩùìÆùìª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8323 rows √ó 22486 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000th  00ano5u6jn  00pm  01  010101  01aqjixwaw  01h  02  ...  \\\n",
       "0      0    0      0           0     0   0       0           0    0   0  ...   \n",
       "1      0    0      0           0     0   0       0           0    0   0  ...   \n",
       "2      0    0      0           0     0   0       0           0    0   0  ...   \n",
       "3      0    0      0           0     0   0       0           0    0   0  ...   \n",
       "4      0    0      0           0     0   0       0           0    0   0  ...   \n",
       "...   ..  ...    ...         ...   ...  ..     ...         ...  ...  ..  ...   \n",
       "8318   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "8319   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "8320   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "8321   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "8322   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "\n",
       "      „ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô  „Åä„Åä„Åç„Å´  „Éï„É¨„ÉÉ„Ç∑„É•„Éç„Çπ„Éê„Éº„Ç¨„Éº  ÂçÉËëâ  Â§ßÈò™  Êù±‰∫¨  Á•ûÊà∏  ùìêùì´ùì∏ùìøùìÆ  ùìóùìÆùì™ùì≠  ùì¶ùì™ùìΩùìÆùìª  \n",
       "0              0     0            0   0   0   0   0      0     0      0  \n",
       "1              0     0            0   0   0   0   0      0     0      0  \n",
       "2              0     0            0   0   0   0   0      0     0      0  \n",
       "3              0     0            0   0   0   0   0      0     0      0  \n",
       "4              0     0            0   0   0   0   0      0     0      0  \n",
       "...          ...   ...          ...  ..  ..  ..  ..    ...   ...    ...  \n",
       "8318           0     0            0   0   0   0   0      0     0      0  \n",
       "8319           0     0            0   0   0   0   0      0     0      0  \n",
       "8320           0     0            0   0   0   0   0      0     0      0  \n",
       "8321           0     0            0   0   0   0   0      0     0      0  \n",
       "8322           0     0            0   0   0   0   0      0     0      0  \n",
       "\n",
       "[8323 rows x 22486 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag-of-Words features\n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(tweets['clean_text'])\n",
    "df_bow = pd.DataFrame(bow.todense(), columns=bow_vectorizer.get_feature_names())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>00ano5u6jn</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010101</th>\n",
       "      <th>01aqjixwaw</th>\n",
       "      <th>01h</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô</th>\n",
       "      <th>„Åä„Åä„Åç„Å´</th>\n",
       "      <th>„Éï„É¨„ÉÉ„Ç∑„É•„Éç„Çπ„Éê„Éº„Ç¨„Éº</th>\n",
       "      <th>ÂçÉËëâ</th>\n",
       "      <th>Â§ßÈò™</th>\n",
       "      <th>Êù±‰∫¨</th>\n",
       "      <th>Á•ûÊà∏</th>\n",
       "      <th>ùìêùì´ùì∏ùìøùìÆ</th>\n",
       "      <th>ùìóùìÆùì™ùì≠</th>\n",
       "      <th>ùì¶ùì™ùìΩùìÆùìª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22486 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000th  00ano5u6jn  00pm  01  010101  01aqjixwaw  01h  02  ...  \\\n",
       "0   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "1   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "2   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "3   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "4   0    0      0           0     0   0       0           0    0   0  ...   \n",
       "\n",
       "   „ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô  „Åä„Åä„Åç„Å´  „Éï„É¨„ÉÉ„Ç∑„É•„Éç„Çπ„Éê„Éº„Ç¨„Éº  ÂçÉËëâ  Â§ßÈò™  Êù±‰∫¨  Á•ûÊà∏  ùìêùì´ùì∏ùìøùìÆ  ùìóùìÆùì™ùì≠  ùì¶ùì™ùìΩùìÆùìª  \n",
       "0           0     0            0   0   0   0   0      0     0      0  \n",
       "1           0     0            0   0   0   0   0      0     0      0  \n",
       "2           0     0            0   0   0   0   0      0     0      0  \n",
       "3           0     0            0   0   0   0   0      0     0      0  \n",
       "4           0     0            0   0   0   0   0      0     0      0  \n",
       "\n",
       "[5 rows x 22486 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for test dataset\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.transform(testset['clean_text'])\n",
    "df_bow_test = pd.DataFrame(bow.todense(), columns=bow_vectorizer.get_feature_names())\n",
    "df_bow_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Bag of Words to Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation set\n",
    "X = df_bow\n",
    "y = tweets['gender']\n",
    "\n",
    "# Use Bag-of-Words Features\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting on Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85447656, 0.14552344],\n",
       "       [0.12522754, 0.87477246],\n",
       "       [0.69917376, 0.30082624],\n",
       "       ...,\n",
       "       [0.64009378, 0.35990622],\n",
       "       [0.40174476, 0.59825524],\n",
       "       [0.44290804, 0.55709196]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first part of the list is predicting probabilities for gender:0 (male)\n",
    "# The second part of the list is predicting probabilities for gender:1 (female)\n",
    "prediction_bow = logreg.predict_proba(X_test_bow)\n",
    "prediction_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787564766839378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the F1 score\n",
    "# If prediction is greater than or equal to 0.3 than 1, else 0\n",
    "# Where 0 is for male tweets and 1 is for female tweets\n",
    "prediction_int = prediction_bow[:,1]>=0.5\n",
    "\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int\n",
    "\n",
    "# Calculating f1 score\n",
    "log_bow = f1_score(y_test_bow, prediction_int)\n",
    "\n",
    "log_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with separate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.18884943]),\n",
       " array([[-0.50990811,  0.65993565,  0.02384009, ...,  0.15187552,\n",
       "          0.15187552,  0.15187552]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is a fit model\n",
    "logreg.intercept_, logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54249864, 0.45750136],\n",
       "       [0.49800956, 0.50199044],\n",
       "       [0.59343196, 0.40656804],\n",
       "       [0.70924953, 0.29075047],\n",
       "       [0.65759751, 0.34240249]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = df_bow_test\n",
    "pred = logreg.predict_proba(z)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = logreg.predict(z)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.542499</td>\n",
       "      <td>0.457501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.501990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.406568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.709250</td>\n",
       "      <td>0.290750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>0.342402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.542499  0.457501\n",
       "1  0.498010  0.501990\n",
       "2  0.593432  0.406568\n",
       "3  0.709250  0.290750\n",
       "4  0.657598  0.342402"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=pred)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_gender\n",
       "0                 0\n",
       "1                 1\n",
       "2                 0\n",
       "3                 0\n",
       "4                 0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = pd.DataFrame(data=pred2, columns=['predicted_gender'])\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>length</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>My statement on the death of George Floyd: htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>statement death George Floyd</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>If you believe in a more just, more generous, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>believe more just more generous more democrati...</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>On Memorial Day, we honor those who gave all f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Memorial honor those gave That takes different...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>And here‚Äôs more on the approach Sweden has tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>here more approach Sweden taken which differs ...</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>South Korea has focused on testing to guard ag...</td>\n",
       "      <td>0</td>\n",
       "      <td>South Korea focused testing guard against outb...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         user                                               text  \\\n",
       "0           0  BarackObama  My statement on the death of George Floyd: htt...   \n",
       "1           1  BarackObama  If you believe in a more just, more generous, ...   \n",
       "2           2  BarackObama  On Memorial Day, we honor those who gave all f...   \n",
       "3           3  BarackObama  And here‚Äôs more on the approach Sweden has tak...   \n",
       "4           4  BarackObama  South Korea has focused on testing to guard ag...   \n",
       "\n",
       "   gender                                         clean_text  length  \\\n",
       "0       0                       statement death George Floyd      66   \n",
       "1       0  believe more just more generous more democrati...     140   \n",
       "2       0  Memorial honor those gave That takes different...     140   \n",
       "3       0  here more approach Sweden taken which differs ...     117   \n",
       "4       0  South Korea focused testing guard against outb...      87   \n",
       "\n",
       "   predicted_gender  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.join(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF features (Term Frequency-Inverse Document Frequency)\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix=tfidf.fit_transform(tweets['clean_text'])\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the test dataset\n",
    "# TF-IDF features (Term Frequency-Inverse Document Frequency)\n",
    "tfidf_matrix=tfidf.transform(testset['clean_text'])\n",
    "df_tfidf_test = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names())\n",
    "df_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF-IDF to Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation set\n",
    "X = df_tfidf\n",
    "y = tweets['gender']\n",
    "\n",
    "# Use Bag-of-Words Features\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF Features\n",
    "logreg.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tfidf = logreg.predict_proba(X_test_tfidf)\n",
    "prediction_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the F1 score\n",
    "prediction_int = prediction_tfidf[:,1]>=0.5\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int\n",
    "\n",
    "# calculating f1 score\n",
    "log_tfidf = f1_score(y_test_tfidf, prediction_int)\n",
    "log_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bag of Words as features\n",
    "dtc.fit(X_train_bow, y_train_bow)\n",
    "dtc_bow = dtc.predict_proba(X_test_bow)\n",
    "dtc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dtc_bow = dtc_bow[:,1]>=0.5\n",
    "\n",
    "# converting the results to integer type\n",
    "dtc_int_bow=dtc_bow.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "dtc_score_bow=f1_score(y_test_bow, dtc_int_bow)\n",
    "\n",
    "dtc_score_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF\n",
    "dtc.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_tfidf = dtc.predict_proba(X_test_tfidf)\n",
    "\n",
    "dtc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dtc_tfidf=dtc_tfidf[:,1]>=0.3\n",
    "\n",
    "# converting the results to integer type\n",
    "dtc_int_tfidf=dtc_tfidf.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "dtc_score_tfidf=f1_score(y_test_tfidf,dtc_int_tfidf)\n",
    "\n",
    "dtc_score_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "Algo=['LogisticRegression(Bag-of-Words)','DecisionTree(Bag-of-Words)','LogisticRegression(TF-IDF)','DecisionTree(TF-IDF)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [log_bow,dct_score_bow,log_tfidf,dct_score_tfidf]\n",
    "\n",
    "compare=pd.DataFrame({'Model':Algo,'F1_Score':score},index=[i for i in range(1,5)])\n",
    "compare.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "sns.pointplot(x='Model',y='F1_Score',data=compare)\n",
    "\n",
    "plt.title('Model Vs Score')\n",
    "plt.xlabel('MODEL')\n",
    "plt.ylabel('SCORE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test With Real Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg.intercept_, Log_Reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.read_csv('../Data/tweetstest.csv')\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_vectorizer.transform(test_text['clean_text']) #use .transform() not .fit_transform()\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bow = Log_Reg.predict_proba(X)\n",
    "prediction_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"this is a test tweet to predict my gender baby boo\"\n",
    "\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.fit_transform('test_text')\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am so angry\"\n",
    "textBlob = TextBlob(text)\n",
    "print(f\"{textBlob.sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
